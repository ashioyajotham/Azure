https://docs.microsoft.com/en-us/learn/modules/train-evaluate-deep-learn-models/3-exercise-train-deep-neural-network

Deep learning is an advanced form of machine learning that tries to emulate the way the human brain learns.
Deep learning emulates this biological process using artificial neural networks that process numeric inputs rather than electrochemical stimuli.

                 ### Deep Neural Network Concepts
Before exploring how to train a deep neural network (DNN) machine learning model, let's consider what we're trying to achieve. 
Machine learning is concerned with predicting a label based on some features of a particular observation. 
In simple terms, a machine learning model is a function that calculates y (the label) from x (the features): f(x)=y.


### A deep neural network (DNN) model
// So how would we use deep learning to build a classification model for the penguin classification model? 
// The deep neural network model for the classifier consists of multiple layers of artificial neurons. In this case, there are four layers:

           * An input layer with a neuron for each expected input (x) value.
           * Two so-called hidden layers, each containing five neurons.
           * An output layer containing three neurons - one for each class probability (y) value to be predicted by the model.
                   
// Because of the layered architecture of the network, this kind of model is sometimes referred to as a multilayer perceptron.
// Additionally, notice that all neurons in the input and hidden layers are connected to all neurons in the subsequent layers - this is an example of a fully connected network.



### Training a DNN
// The training process for a deep neural network consists of multiple iterations, called epochs. 
// For the first epoch, you start by assigning random initialization values for the weight (w) and bias b values. Then the process is as follows:
           * Features for data observations with known label values are submitted to the input layer. 
              Generally, these observations are grouped into batches (often referred to as mini-batches).
           * The neurons then apply their function, and if activated, pass the result onto the next layer until the output layer produces a prediction.
           * The prediction is compared to the actual known value, and the amount of variance between the predicted and true values (which we call the loss) is calculated.
           * Based on the results, revised values for the weights and bias values are calculated to reduce the loss, and these adjustments are backpropagated to the neurons in the network layers.
           * The next epoch repeats the batch training forward pass with the revised weight and bias values, hopefully improving the accuracy of the model (by reducing the loss).
           
N/B:          
Processing the training features as a batch improves the efficiency of the training process by processing multiple observations simultaneously 
as a matrix of features with vectors of weights and biases. Linear algebraic functions that operate with matrices and vectors also feature in 3D graphics processing, 
which is why computers with graphic processing units (GPUs) provide significantly better performance for deep learning model training than central processing unit (CPU) only computers.


### A closer look at loss functions and backpropagation
     ##### Calculating loss
   // Suppose one of the samples passed through the training process contains features of an Adelie specimen (class 0). 
       The correct output from the network would be [1, 0, 0]. Now suppose that the output produced by the network is [0.4, 0.3, 0.3]. 
   Comparing these, we can calculate an absolute variance for each element (in other words, how far is each predicted value away from what it should be) as [0.6, 0.3, 0.3].
    In reality, since we're actually dealing with multiple observations, we typically aggregate the variance - 
      for example by squaring the individual variance values and calculating the mean, so we end up with a single, average loss value, like 0.18.
      
      
     ##### Optimiziers
     // The loss is calculated using a function, which operates on the results from the final layer of the network, which is also a function. 
        The final layer of network operates on the outputs from the previous layers, which are also functions. So in effect, the entire model from the input layer right through to the loss calculation is just one big nested function. 
        Functions have a few really useful characteristics, including:
                     * You can conceptualize a function as a plotted line comparing its output with each of its variables.
                     * You can use differential calculus to calculate the derivative of the function at any point with respect to its variables.
                     * Let's take the first of these capabilities. 
                     * We can plot the line of the function to show how an individual weight value compares to loss, 
                       and mark on that line the point where the current weight value matches the current loss value.
                       
 We use an optimizer for all of the weight and bias variables in the model and determine in which direction we need to adjust them (up or down) to reduce the overall amount of loss in the model. 
  There are multiple commonly used optimization algorithms, including stochastic gradient descent (SGD), Adaptive Learning Rate (ADADELTA), Adaptive Momentum Estimation (Adam), and others; 
  all of which are designed to figure out how to adjust the weights and biases to minimize loss.
  
 
     #### Learning Rate
     The size of the adjustment is controlled by a parameter that you set for training called the learning rate. 
     A low learning rate results in small adjustments (so it can take more epochs to minimize the loss), while a high learning rate results in large adjustments (so you might miss the minimum altogether).

